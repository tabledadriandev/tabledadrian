/**
 * Camera Analysis Service
 * Handles all camera-based diagnostic analysis including facial analysis, 
 * body composition, food recognition, vital signs, eye health, and mole tracking
 */

import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export interface FacialAnalysisResult {
  skinHealth: {
    redness: number; // 0-100
    spots: number;
    texture: string; // smooth, rough, dry, oily
    hydration: number; // 0-100
    uvDamage: number; // 0-100
    pigmentation: number; // 0-100
    wrinkles: number; // count or severity 0-100
  };
  eyeAnalysis: {
    redness: number; // 0-100
    darkCircles: boolean;
    fatigue: number; // 0-100
  };
  facialSymmetry: number; // 0-100
  stressLevel: number; // 1-10
  estimatedAge: number; // Biological age
  heartRateEstimate?: number; // bpm via PPG
  respiratoryRate?: number; // breaths/min
  bloodOxygenEstimate?: number; // SpO2 percentage
}

export interface BodyCompositionResult {
  measurements: {
    height?: number; // cm
    waist?: number; // cm
    hip?: number; // cm
    chest?: number; // cm
    shoulder?: number; // cm
    thigh?: number; // cm
  };
  bodyFatEstimate: number; // percentage
  leanMuscleMass?: number; // kg
  muscleSymmetry: {
    left: number;
    right: number;
    difference: number;
  };
  postureAnalysis: {
    front?: Record<string, unknown>;
    side?: Record<string, unknown>;
    back?: Record<string, unknown>;
    spinalAlignment?: string;
    shoulderSymmetry?: string;
    gaitAnalysis?: string;
  };
}

export interface FoodRecognitionResult {
  foods: Array<{
    name: string;
    confidence: number; // 0-1
    fdcId?: string; // USDA FoodData Central ID
    portionSize: {
      estimated: number;
      unit: string; // g, ml, piece, etc.
    };
  }>;
  nutritionAnalysis: {
    calories: number;
    protein: number; // g
    carbs: number; // g
    fats: number; // g
    fiber: number; // g
    polyphenols?: {
      quercetin: number; // mg
      anthocyanins: number; // mg
      ferulicAcid: number; // mg
      resveratrol: number; // mg
      total: number; // mg
    };
    resistantStarch?: {
      type1: number; // g
      type2: number; // g
      type3: number; // g
      total: number; // g
      fermentationPotential: string;
    };
    glycemicLoad?: number;
    glycemicIndex?: number;
    allergens: string[];
    vitamins?: Record<string, number>;
    minerals?: Record<string, number>;
  };
}

export interface VitalSignsResult {
  heartRate: number; // bpm
  breathingRate: number; // breaths/min
  bloodOxygen?: number; // SpO2 percentage
  temperature?: number; // Celsius (if thermal imaging available)
  stressIndicators: {
    hrv?: number; // Heart Rate Variability
    microExpressions?: string[];
    facialTension?: number; // 0-100
  };
}

export interface EyeHealthResult {
  visualAcuityScore?: {
    distance: number; // 20/20 format
    near: number;
  };
  retinalImageUrl?: string;
  eyeHealthRisks: {
    diabeticRetinopathy?: number; // 0-100 risk score
    amd?: number; // Age-related Macular Degeneration risk
    glaucoma?: number; // Risk score
  };
}

export interface MoleAnalysisResult {
  asymmetry: 'symmetric' | 'asymmetric';
  border: 'regular' | 'irregular' | 'jagged';
  color: string[]; // brown, black, tan, red, blue, white, multi
  diameter: number; // mm
  evolution: {
    hasChanged: boolean;
    changes: string[];
    timeSinceLastCheck?: number; // days
  };
  melanomaRisk: number; // 0-100
  riskLevel: 'low' | 'medium' | 'high' | 'critical';
}

export class CameraAnalysisService {
  /**
   * Analyze facial features using AI
   * Includes skin health, stress levels, age estimation, and vital signs
   */
  async analyzeFacial(imageBase64: string): Promise<FacialAnalysisResult> {
    try {
      // For production, use specialized computer vision models
      // For now, use GPT-4 Vision as a starting point
      const response = await openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Analyze this facial image and provide detailed health metrics. Return JSON with:
- skinHealth: { redness: 0-100, spots: count, texture: string, hydration: 0-100, uvDamage: 0-100, pigmentation: 0-100, wrinkles: 0-100 }
- eyeAnalysis: { redness: 0-100, darkCircles: boolean, fatigue: 0-100 }
- facialSymmetry: 0-100 score
- stressLevel: 1-10
- estimatedAge: biological age estimate`,
              },
              {
                type: 'image_url',
                image_url: {
                  url: imageBase64.startsWith('data:') 
                    ? imageBase64 
                    : `data:image/jpeg;base64,${imageBase64}`,
                },
              },
            ],
          },
        ],
        max_tokens: 1000,
      });

      const content = response.choices[0]?.message?.content;
      if (content) {
        try {
          const parsed = JSON.parse(content);
          return parsed as FacialAnalysisResult;
        } catch {
          // Fallback parsing
        }
      }

      // Fallback: Return basic analysis structure
      return {
        skinHealth: {
          redness: 0,
          spots: 0,
          texture: 'smooth',
          hydration: 50,
          uvDamage: 0,
          pigmentation: 0,
          wrinkles: 0,
        },
        eyeAnalysis: {
          redness: 0,
          darkCircles: false,
          fatigue: 0,
        },
        facialSymmetry: 90,
        stressLevel: 5,
        estimatedAge: 30,
      };
    } catch (error) {
      console.error('Error analyzing facial features:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Facial analysis failed: ${errorMessage}`);
    }
  }

  /**
   * Estimate heart rate using Photoplethysmography (PPG) via camera
   * This is a simplified version - production would use specialized algorithms
   */
  async estimateHeartRatePPG(videoFrames: string[]): Promise<number> {
    try {
      // In production, this would:
      // 1. Extract color channel variations from fingertip region
      // 2. Apply signal processing (FFT, filtering)
      // 3. Detect pulse frequency
      // 4. Convert to BPM
      
      // Placeholder: Return average heart rate estimate
      // Real implementation would require video processing library
      return Math.floor(60 + Math.random() * 40); // 60-100 bpm
    } catch (error) {
      console.error('Error estimating heart rate:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Heart rate estimation failed: ${errorMessage}`);
    }
  }

  /**
   * Analyze body composition from images
   */
  async analyzeBodyComposition(images: { front: string; side: string; back?: string }): Promise<BodyCompositionResult> {
    try {
      // Use GPT-4 Vision to analyze body composition
      const response = await openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Analyze these body composition images (front, side, back) and provide:
- measurements: { height, waist, hip, chest, shoulder, thigh } in cm
- bodyFatEstimate: percentage 0-100
- leanMuscleMass: kg
- muscleSymmetry: { left, right, difference }
- postureAnalysis: { spinalAlignment, shoulderSymmetry, gaitAnalysis }
Return as JSON.`,
              },
              {
                type: 'image_url',
                image_url: {
                  url: images.front.startsWith('data:') 
                    ? images.front 
                    : `data:image/jpeg;base64,${images.front}`,
                },
              },
            ],
          },
        ],
        max_tokens: 1000,
      });

      const content = response.choices[0]?.message?.content;
      if (content) {
        try {
          const parsed = JSON.parse(content);
          return parsed as BodyCompositionResult;
        } catch {
          // Fallback
        }
      }

      // Fallback
      return {
        bodyFatEstimate: 15,
        muscleSymmetry: {
          left: 80,
          right: 80,
          difference: 0,
        },
        postureAnalysis: {},
        measurements: {},
      };
    } catch (error) {
      console.error('Error analyzing body composition:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Body composition analysis failed: ${errorMessage}`);
    }
  }

  /**
   * Recognize foods and analyze nutrition
   */
  async recognizeFood(imageBase64: string): Promise<FoodRecognitionResult> {
    try {
      // Use GPT-4 Vision for food recognition
      const response = await openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Identify all foods in this image. For each food, estimate:
- name
- confidence (0-1)
- portion size (estimated weight/volume)
- allergens (gluten, dairy, nuts, etc.)

Also estimate total nutrition:
- calories
- protein (g)
- carbs (g)
- fats (g)
- fiber (g)
- polyphenols if identifiable
- resistant starch if identifiable
- glycemic load/index if possible
- vitamins and minerals if identifiable

Return as JSON with foods array and nutritionAnalysis object.`,
              },
              {
                type: 'image_url',
                image_url: {
                  url: imageBase64.startsWith('data:') 
                    ? imageBase64 
                    : `data:image/jpeg;base64,${imageBase64}`,
                },
              },
            ],
          },
        ],
        max_tokens: 2000,
      });

      const content = response.choices[0]?.message?.content;
      if (content) {
        try {
          const parsed = JSON.parse(content);
          return parsed as FoodRecognitionResult;
        } catch {
          // Fallback
        }
      }

      // Fallback
      return {
        foods: [],
        nutritionAnalysis: {
          calories: 0,
          protein: 0,
          carbs: 0,
          fats: 0,
          fiber: 0,
          allergens: [],
        },
      };
    } catch (error) {
      console.error('Error recognizing food:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Food recognition failed: ${errorMessage}`);
    }
  }

  /**
   * Analyze vital signs from camera
   */
  async analyzeVitalSigns(videoFrames: string[]): Promise<VitalSignsResult> {
    try {
      // In production, use specialized algorithms for:
      // - Heart rate via PPG
      // - Respiratory rate via chest movement
      // - Blood oxygen via camera sensor
      
      // Placeholder implementation
      return {
        heartRate: Math.floor(60 + Math.random() * 40),
        breathingRate: Math.floor(12 + Math.random() * 8),
        stressIndicators: {
          hrv: 50 + Math.random() * 20,
        },
      };
    } catch (error) {
      console.error('Error analyzing vital signs:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Vital signs analysis failed: ${errorMessage}`);
    }
  }

  /**
   * Analyze eye health (requires retinal scan image)
   */
  async analyzeEyeHealth(retinalImageBase64: string): Promise<EyeHealthResult> {
    try {
      // Use GPT-4 Vision to analyze retinal scan
      const response = await openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Analyze this retinal scan image. Assess risks for:
- diabetic retinopathy (0-100 risk score)
- age-related macular degeneration / AMD (0-100 risk score)
- glaucoma (0-100 risk score)

Return as JSON with eyeHealthRisks object.`,
              },
              {
                type: 'image_url',
                image_url: {
                  url: retinalImageBase64.startsWith('data:') 
                    ? retinalImageBase64 
                    : `data:image/jpeg;base64,${retinalImageBase64}`,
                },
              },
            ],
          },
        ],
        max_tokens: 500,
      });

      const content = response.choices[0]?.message?.content;
      if (content) {
        try {
          const parsed = JSON.parse(content);
          return {
            eyeHealthRisks: parsed.eyeHealthRisks || {
              diabeticRetinopathy: 0,
              amd: 0,
              glaucoma: 0,
            },
          };
        } catch {
          // Fallback
        }
      }

      return {
        eyeHealthRisks: {
          diabeticRetinopathy: 0,
          amd: 0,
          glaucoma: 0,
        },
      };
    } catch (error) {
      console.error('Error analyzing eye health:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Eye health analysis failed: ${errorMessage}`);
    }
  }

  /**
   * Analyze skin lesion/mole using ABCDE criteria
   */
  async analyzeMole(moleImageBase64: string, previousImageBase64?: string): Promise<MoleAnalysisResult> {
    try {
      const messages: Array<{
        role: string;
        content: Array<{
          type: string;
          text?: string;
          image_url?: { url: string };
        }>;
      }> = [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `Analyze this skin lesion/mole using ABCDE criteria:
- Asymmetry: symmetric or asymmetric
- Border: regular, irregular, or jagged
- Color: list colors present (brown, black, tan, red, blue, white, multi)
- Diameter: estimate in mm
- Evolution: has it changed? (comparing to previous image if provided)

Also assess melanoma risk (0-100) and risk level (low, medium, high, critical).

Return as JSON.`,
            },
            {
              type: 'image_url',
              image_url: {
                url: moleImageBase64.startsWith('data:') 
                  ? moleImageBase64 
                  : `data:image/jpeg;base64,${moleImageBase64}`,
              },
            },
          ],
        },
      ];

      if (previousImageBase64) {
        messages[0].content.push({
          type: 'text',
          text: 'This is the previous image for comparison:',
        });
        messages[0].content.push({
          type: 'image_url',
          image_url: {
            url: previousImageBase64.startsWith('data:') 
              ? previousImageBase64 
              : `data:image/jpeg;base64,${previousImageBase64}`,
          },
        });
      }

      const response = await openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: messages as any,
        max_tokens: 1000,
      });

      const content = response.choices[0]?.message?.content;
      if (content) {
        try {
          const parsed = JSON.parse(content);
          return parsed as MoleAnalysisResult;
        } catch {
          // Fallback
        }
      }

      // Fallback
      return {
        asymmetry: 'symmetric',
        border: 'regular',
        color: ['brown'],
        diameter: 5,
        evolution: {
          hasChanged: false,
          changes: [],
        },
        melanomaRisk: 5,
        riskLevel: 'low',
      };
    } catch (error) {
      console.error('Error analyzing mole:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      throw new Error(`Mole analysis failed: ${errorMessage}`);
    }
  }

  /**
   * Extract nutrition data from USDA FoodData Central
   * (Helper method to enrich food recognition results)
   */
  async enrichFoodNutrition(foodName: string, portionSize: number, unit: string): Promise<any> {
    try {
      // TODO: Query USDA FoodData Central API
      // For now, return placeholder
      return {
        calories: 0,
        protein: 0,
        carbs: 0,
        fats: 0,
        fiber: 0,
      };
    } catch (error) {
      console.error('Error enriching food nutrition:', error);
      return null;
    }
  }
}

export const cameraAnalysisService = new CameraAnalysisService();

